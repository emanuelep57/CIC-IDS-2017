{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **NETWORK INTRUSION DETECTION SYSTEM (NIDS)**\n",
    "## **Fase 2: Advanced Preprocessing, Feature Engineering & Selection**\n",
    "\n",
    "### **Obiettivo Strategico**\n",
    "\n",
    "Questo notebook trasforma i dati grezzi in un dataset ottimizzato per il Machine Learning, eliminando il rumore e i bias topologici, e arricchendo l'informazione tramite Feature Engineering mirato.\n",
    "\n",
    "### **Metodologia :**\n",
    "\n",
    "1. **Sanitizzazione Anti-Bias**: Rimozione tassativa di feature topologiche. Catillo et al. (2022) dimostrano che mantenere questi campi porta a *Data-Induced Leakage*, dove il modello impara la rete specifica invece dell'attacco.\n",
    "\n",
    "2. **Variance Threshold**: Rimozione di feature quasi-costanti che non contribuiscono alla discriminazione\n",
    "\n",
    "3. **Multicollinearity Analysis**: Identificazione e rimozione di feature ridondanti con correlazione > 0.95. L'obiettivo √® ridurre il rischio di overfitting e migliorare l'interpretabilit√†\n",
    "\n",
    "4. **Multiple Feature Selection Methods**: Combinazione di metodi complementari:\n",
    "   - **Filter-based**: Correlation, Mutual Information, ANOVA F-test\n",
    "   - **Embedded**: Random Forest Feature Importance\n",
    "   - **Consensus Ranking**: Aggregazione dei risultati per identificare le feature pi√π robuste\n",
    "\n",
    "5. **Strict Data Splitting**: Suddivisione Stratificata 70/15/15. Il Validation Set √® isolato per scegliere il modello migliore, il Test Set per il Benchmark finale.\n",
    "\n",
    "7. **No-Leakage Policy**: SMOTE e Scaling **NON** vengono applicati in questo notebook. Verranno integrati dinamicamente nelle pipeline di training nel notebook successivo per evitare la contaminazione del Validation Set.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. SETUP AMBIENTE**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 1. SETUP AMBIENTE\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import gc\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import (\n",
    "    SelectFromModel,\n",
    "    VarianceThreshold,\n",
    "    f_classif,\n",
    "    mutual_info_classif,\n",
    ")\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Configurazione Plotting SOTA-Style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 120\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Variabili di Stato (Riproducibilit√†)\n",
    "STATE_VARS = {\n",
    "    'RANDOM_SEED': 42,\n",
    "    'TEST_SIZE': 0.15,\n",
    "    'VAL_SIZE_REL': 0.1765,  # 15% del totale, calcolato sul residuo dell'85%\n",
    "    'CORR_THRESHOLD': 0.95,\n",
    "    'RF_N_ESTIMATORS': 100,\n",
    "    'N_FEATURES_FINAL': 20,  # Numero finale di feature da selezionare\n",
    "}\n",
    "\n",
    "# Path Management - CORRETTI\n",
    "DATA_PATH = '../output'  # Qui sta cicids2017_cleaned.parquet\n",
    "OUTPUT_PATH = '../output/processed_datasets'  # Output finale\n",
    "INTERMEDIATE_PATH = '../output/feature_analysis'  # Analisi intermedie\n",
    "IMG_PATH = '../output/images/preprocessing'  # Immagini\n",
    "\n",
    "for p in [OUTPUT_PATH, INTERMEDIATE_PATH, IMG_PATH]:\n",
    "    os.makedirs(p, exist_ok=True)\n",
    "\n",
    "print(\" Setup completato. Librerie caricate.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Caricamento e Sanitizzazione Anti-Bias**\n",
    "\n",
    "### **Fondamento Teorico: Data-Induced Leakage**\n",
    "\n",
    "**Problema:** I sistemi NIDS tradizionali includono identificatori di rete che creano **dipendenze topologiche**.\n",
    "\n",
    "**Soluzione:** Rimozione completa delle feature topologiche:\n",
    "**Destination Port**: Identificatore di servizio specifico della rete di test\n",
    "\n",
    "### **Safety Check: Leakage della Label**\n",
    "Verifichiamo che `Label` e `LabelEncoded` **NON** entrino mai nel set di feature `X`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"[1/5] Caricamento Dataset...\")\n",
    "\n",
    "try:\n",
    "    df = pd.read_parquet(os.path.join(DATA_PATH, \"cicids2017_cleaned.parquet\"))\n",
    "    print(f\" Dataset caricato. Shape: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"File Parquet non trovato! Assicurati di aver eseguito il Notebook 01.\")\n",
    "\n",
    "# --- SANITIZZAZIONE ---\n",
    "identifiers = [\n",
    "    'Destination Port',\n",
    "    # Nota: Source/Destination IP non presenti nel dataset -> controllato features\n",
    "]\n",
    "\n",
    "# Feature Leakage: LabelEncoded non deve stare in X\n",
    "leakage_cols = ['Label_Encoded']\n",
    "\n",
    "cols_to_drop = [c for c in identifiers + leakage_cols if c in df.columns]\n",
    "\n",
    "if cols_to_drop:\n",
    "    df.drop(columns=cols_to_drop, inplace=True)\n",
    "    print(f\" Sanitizzazione: Rimossi {len(cols_to_drop)} identificatori e colonne leakage.\")\n",
    "    print(f\"   rimossi: {cols_to_drop}\")\n",
    "\n",
    "print(f\" Shape post-sanitizzazione: {df.shape}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Feature Engineerimg**\n",
    "\n",
    "### **Fondamento Teorico: Ratio Features per Attacchi Asimmetrici**\n",
    "\n",
    "**Problema:** Gli attacchi moderni alterano la **simmetria bidirezionale** del traffico:\n",
    "- **DoS/DDoS**: Flood unidirezionale ‚Üí Molti pacchetti Forward, pochi/zero Backward\n",
    "- **Port Scan**: Probing rapido ‚Üí Pacchetti piccoli Forward, timeout Backward\n",
    "- **Botnet C&C**: Comunicazione asimmetrica ‚Üí Comandi piccoli, risposte grandi\n",
    "\n",
    "Abbiamo introdotto **Ratio Features** per catturare queste asimmetrie:\n",
    "\n",
    "### **Feature Ingegnerizzate:**\n",
    "\n",
    "#### **1. PacketRatio = Fwd Packets / Bwd Packets**\n",
    "- **Traffico Normale**: Ratio ‚âà 1 (simmetria TCP handshake, richiesta/risposta HTTP)\n",
    "- **DoS Attack**: Ratio >> 1 (flood unidirezionale, nessuna risposta)\n",
    "- **Invarianza Temporale**: Non dipende dalla durata del flusso\n",
    "\n",
    "#### **2. ByteRatio = Fwd Bytes / Bwd Bytes**\n",
    "- **Traffico Normale**: Ratio variabile ma bilanciato\n",
    "- **Data Exfiltration**: Ratio << 1 (comandi piccoli, dati estratti grandi)\n",
    "- **C&C Communication**: Ratio asimmetrico caratteristico\n",
    "\n",
    "### **Vantaggi:**\n",
    "1. **Robustezza**: Invarianti rispetto alla scala temporale del flusso\n",
    "2. **Generalizzazione**: Catturano pattern d'attacco, non caratteristiche di rete\n",
    "3. **Interpretabilit√†**: Valori > 1 o < 1 hanno significato semantico diretto"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"[2/5] Feature Engineering FLARE Ratios...\")\n",
    "\n",
    "# 1. Packet Ratio (Simmetria pacchetti)\n",
    "df['PacketRatio'] = np.where(\n",
    "    df['Total Backward Packets'] == 0,\n",
    "    0,\n",
    "    df['Total Fwd Packets'] / df['Total Backward Packets'],\n",
    ")\n",
    "\n",
    "# 2. Byte Ratio (Simmetria payload)\n",
    "df['ByteRatio'] = np.where(\n",
    "    df['Total Length of Bwd Packets'] == 0,\n",
    "    0,\n",
    "    df['Total Length of Fwd Packets'] / df['Total Length of Bwd Packets'],\n",
    ")\n",
    "\n",
    "# Gestione infiniti e NaN generati dalla divisione\n",
    "df.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "print(\" Feature create: PacketRatio, ByteRatio\")\n",
    "\n",
    "# Separazione X e y\n",
    "target_col = 'Label'\n",
    "X = df.drop(columns=target_col)\n",
    "y = df[target_col]\n",
    "\n",
    "# SAFETY CHECK RIGOROSO\n",
    "assert 'Label' not in X.columns, \" ERRORE CRITICO: La Label √® in X!\"\n",
    "assert 'LabelEncoded' not in X.columns, \" ERRORE CRITICO: LabelEncoded √® in X!\"\n",
    "print(\" Safety Check Passato: Nessun target nelle feature.\")\n",
    "\n",
    "del df\n",
    "gc.collect()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Stratified Data Splitting**\n",
    "\n",
    "### **Fondamento Teorico: Train/Val/Test Isolation**\n",
    "\n",
    "**Problema dello Sbilanciamento Estremo:**\n",
    "CIC-IDS-2017 presenta classi rare:\n",
    "- **Heartbleed**: 11 campioni (0.001%)\n",
    "- **Infiltration**: 36 campioni (0.004%)\n",
    "- **BENIGN**: 2,273,097 campioni (80%)\n",
    "\n",
    "### **Split 70/15/15 Stratificato:**\n",
    "1. **Train Set (70%)**: Addestramento + Feature Selection\n",
    "   - Feature Selection calcolata **SOLO** su Train per evitare leakage\n",
    "2. **Validation Set (15%)**: Valutazione dei modelli\n",
    "   - NON toccare durante Feature Selection\n",
    "3. **Test Set (15%)**: Benchmark finale\n",
    "   - Completamente isolato fino alla valutazione finale\n",
    "   - Simula deployment reale\n",
    "\n",
    "### **Stratificazione (`stratify=y`):**\n",
    "- Garantisce che classi rare (Heartbleed, Infiltration) siano presenti in tutti i set\n",
    "- Mantiene distribuzione proporzionale: Train/Val/Test hanno stesse proporzioni di attacchi"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"[3/5] Data Splitting Stratificato (70/15/15)...\")\n",
    "\n",
    "# Split 1: Train+Val vs Test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=STATE_VARS['TEST_SIZE'],\n",
    "    stratify=y,\n",
    "    random_state=STATE_VARS['RANDOM_SEED'],\n",
    ")\n",
    "\n",
    "# Split 2: Train vs Val\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=STATE_VARS['VAL_SIZE_REL'],\n",
    "    stratify=y_temp,\n",
    "    random_state=STATE_VARS['RANDOM_SEED'],\n",
    ")\n",
    "\n",
    "print(f\" Train Set: {X_train.shape[0]:,} samples\")\n",
    "print(f\" Val Set: {X_val.shape[0]:,} samples\")\n",
    "print(f\" Test Set: {X_test.shape[0]:,} samples\")\n",
    "\n",
    "del X, y, X_temp, y_temp\n",
    "gc.collect()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Feature Selection Pipeline SOTA**\n",
    "\n",
    "### **Fondamento Teorico: Ensemble Feature Selection**\n",
    "\n",
    "**Problema:** Metodi singoli di Feature Selection hanno bias:\n",
    "- **Correlation**: Cattura solo relazioni lineari\n",
    "- **Mutual Information**: Computazionalmente costosa, pu√≤ overfittare\n",
    "- **Random Forest**: Bias verso feature ad alta cardinalit√†\n",
    "- **ANOVA F-test**: Assume normalit√†\n",
    "\n",
    "**Tripathi et al. (2024)** e **Agarwala et al. (2024)** propongono **Consensus Ranking**:\n",
    "\n",
    "### **Strategia Multi-Method:**\n",
    "1. **Filter Methods** (veloci, no training):\n",
    "   - Spearman Correlation: Associazione monotonica con target\n",
    "   - Mutual Information: Dipendenza non lineare\n",
    "   - ANOVA F-test: Differenze tra medie di classe\n",
    "\n",
    "2. **Embedded Method** (considera interazioni):\n",
    "   - Random Forest Importance: Valuta feature durante training\n",
    "\n",
    "3. **Consensus Aggregation**:\n",
    "   - Ranking medio dei 4 metodi\n",
    "   - Riduce overfitting su metodo singolo\n",
    "   - Identifica feature robuste su criteri multipli\n",
    "\n",
    "### **Anti-Leakage Policy:**\n",
    "Tutte le statistiche (varianza, correlazione, importanza) calcolate **SOLO su X_train**, poi applicate a Val/Test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.1 Variance Threshold**\n",
    "\n",
    "**Teoria:** Feature con varianza ‚âà 0 sono **quasi-costanti** e non forniscono informazione discriminante.\n",
    "\n",
    "**Implementazione:** Rimuoviamo feature con `Var(X) = 0.01` (quasi costanti)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"[4/5] Feature Selection Pipeline SOTA...\\n\")\n",
    "\n",
    "# A. Variance Threshold\n",
    "print(\"1. Variance Threshold...\")\n",
    "var_selector = VarianceThreshold(threshold=0.01)\n",
    "var_selector.fit(X_train)\n",
    "feat_var = X_train.columns[var_selector.get_support()]\n",
    "\n",
    "X_train_v = X_train.loc[:, feat_var]\n",
    "removed_var = X_train.shape[1] - len(feat_var)\n",
    "print(f\"    {removed_var} feature rimosse. Rimaste: {X_train_v.shape[1]}\")\n",
    "\n",
    "# Salva output\n",
    "low_var_features = X_train.columns[~var_selector.get_support()].tolist()\n",
    "with open(os.path.join(INTERMEDIATE_PATH, \"06_low_variance_features.json\"), 'w') as f:\n",
    "    json.dump(low_var_features, f, indent=2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.2 Correlation Filter ‚â• 0.95**\n",
    "\n",
    "**Teoria:** Feature altamente correlate (|r| ‚â• 0.95) sono **ridondanti** e causano:\n",
    "1. **Multicollinearit√†**: Instabilit√† nei coefficienti del modello\n",
    "2. **Overfitting**: Il modello memorizza rumore correlato\n",
    "\n",
    "**Implementazione:**\n",
    "- Calcolo matrice di correlazione di Pearson\n",
    "- Identificazione coppie con |r| ‚â• 0.95\n",
    "- Rimozione di una feature per coppia (manteniamo quella con ranking migliore)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# B. Correlation Filter\n",
    "print(\"\\n2. Correlation Filter ‚â• 0.95...\")\n",
    "corr_matrix = X_train_v.corr().abs()\n",
    "upper = corr_matrix.where(\n",
    "    np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    ")\n",
    "\n",
    "# Trova coppie con correlazione alta\n",
    "high_corr_pairs = []\n",
    "for column in upper.columns:\n",
    "    if any(upper[column] >= STATE_VARS['CORR_THRESHOLD']):\n",
    "        for idx in upper.index[upper[column] >= STATE_VARS['CORR_THRESHOLD']]:\n",
    "            high_corr_pairs.append({\n",
    "                'Feature1': column,\n",
    "                'Feature2': idx,\n",
    "                'Correlation': upper.loc[idx, column],\n",
    "            })\n",
    "\n",
    "# Salva coppie multicollineari\n",
    "if high_corr_pairs:\n",
    "    pd.DataFrame(high_corr_pairs).to_csv(\n",
    "        os.path.join(INTERMEDIATE_PATH, \"09_multicollinearity_pairs.csv\"),\n",
    "        index=False,\n",
    "    )\n",
    "\n",
    "# Rimuovi feature ridondanti\n",
    "to_drop_corr = [column for column in upper.columns if any(upper[column] >= STATE_VARS['CORR_THRESHOLD'])]\n",
    "X_train_c = X_train_v.drop(columns=to_drop_corr)\n",
    "\n",
    "print(f\"    {len(to_drop_corr)} feature rimosse. Rimaste: {X_train_c.shape[1]}\")\n",
    "\n",
    "# Salva candidati alla rimozione\n",
    "drop_candidates = {'multicollinearity_candidates': to_drop_corr}\n",
    "with open(os.path.join(INTERMEDIATE_PATH, \"10_multicollinearity_drop_candidates.json\"), 'w') as f:\n",
    "    json.dump(drop_candidates, f, indent=2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.3 Feature-Target Correlation (Spearman)**\n",
    "\n",
    "**Teoria:** Correlazione di Spearman misura **associazione monotonica** (non necessariamente lineare) tra feature e target.\n",
    "\n",
    "**Vantaggi vs Pearson:**\n",
    "- Robusta a outlier\n",
    "- Cattura relazioni non lineari monotone\n",
    "- Non assume distribuzione normale\n",
    "\n",
    "**Interpretazione:** rho ‚àà [-1, 1]\n",
    "- |œÅ| ‚âà 1: Forte associazione monotonica\n",
    "- |œÅ| ‚âà 0: Nessuna associazione monotonica\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# C. Feature-Target Correlation (Spearman)\n",
    "print(\"\\n3. Feature-Target Correlation (Spearman)...\")\n",
    "\n",
    "# Encode target per correlazione\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "\n",
    "corr_results = []\n",
    "for col in X_train_c.columns:\n",
    "    try:\n",
    "        corr, p_val = spearmanr(X_train_c[col], y_train_encoded)\n",
    "        corr_results.append({\n",
    "            'Feature': col,\n",
    "            'SpearmanCorr': abs(corr),\n",
    "            'CorrSign': np.sign(corr),\n",
    "            'pvalue': p_val,\n",
    "        })\n",
    "    except:\n",
    "        corr_results.append({\n",
    "            'Feature': col,\n",
    "            'SpearmanCorr': np.nan,\n",
    "            'CorrSign': np.nan,\n",
    "            'pvalue': np.nan,\n",
    "        })\n",
    "\n",
    "corr_df = pd.DataFrame(corr_results).sort_values('SpearmanCorr', ascending=False)\n",
    "corr_df.to_csv(os.path.join(INTERMEDIATE_PATH, \"08_feature_target_correlation.csv\"), index=False)\n",
    "\n",
    "print(f\"    Correlazioni calcolate per {len(corr_df)} feature\")\n",
    "print(f\"   Top 5 feature correlate al target:\")\n",
    "print(corr_df.head()[['Feature', 'SpearmanCorr']].to_string(index=False))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.4 Mutual Information**\n",
    "\n",
    "**Teoria:** Mutual Information (MI) misura la **dipendenza statistica generale** tra feature e target, catturando anche relazioni **non lineari** e **non monotone**.\n",
    "\n",
    "**Complementarit√† con Correlazione:**\n",
    "- Correlazione: Solo relazioni lineari/monotone\n",
    "- MI: Qualsiasi dipendenza statistica\n",
    "\n",
    "**Esempio:** Feature con correlazione bassa ma MI alta ‚Üí Relazione non lineare importante!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# D. Mutual Information\n",
    "print(\"\\n4. Mutual Information (pu√≤ richiedere qualche minuto)...\")\n",
    "\n",
    "mi_scores = mutual_info_classif(\n",
    "    X_train_c, y_train_encoded,\n",
    "    random_state=STATE_VARS['RANDOM_SEED'], n_jobs=-1,\n",
    ")\n",
    "\n",
    "mi_df = pd.DataFrame({\n",
    "    'Feature': X_train_c.columns,\n",
    "    'MI_Score': mi_scores,\n",
    "}).sort_values('MI_Score', ascending=False)\n",
    "\n",
    "mi_df.to_csv(os.path.join(INTERMEDIATE_PATH, \"11_mutual_information_scores.csv\"), index=False)\n",
    "\n",
    "print(f\"    MI calcolata per {len(mi_df)} feature\")\n",
    "print(f\"    Top 5 feature per MI:\")\n",
    "print(mi_df.head()[['Feature', 'MI_Score']].to_string(index=False))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.5 ANOVA F-test**\n",
    "\n",
    "**Teoria:** ANOVA (Analysis of Variance) F-test valuta se le **medie di una feature differiscono significativamente tra le classi**.\n",
    "\n",
    "**Utilit√† per questo dataset:**\n",
    "CIC-IDS-2017 ha 15 classi (BENIGN + 14 attacchi) -> ridotte ad 8. ANOVA identifica feature che separano bene **tutte** le classi contemporaneamente.\n",
    "\n",
    "**Assunzioni (tollerabili con grandi dataset):**\n",
    "- Normalit√†\n",
    "- Varianza simile\n",
    "\n",
    "**p-value < 0.05:** Differenze statisticamente significative"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# E. ANOVA F-test\n",
    "print(\"\\n5. ANOVA F-test...\")\n",
    "\n",
    "f_scores, f_pvalues = f_classif(X_train_c, y_train_encoded)\n",
    "\n",
    "anova_df = pd.DataFrame({\n",
    "    'Feature': X_train_c.columns,\n",
    "    'F_Statistic': f_scores,\n",
    "    'pvalue': f_pvalues,\n",
    "}).sort_values('F_Statistic', ascending=False)\n",
    "\n",
    "anova_df.to_csv(os.path.join(INTERMEDIATE_PATH, \"12_anova_f_statistics.csv\"), index=False)\n",
    "\n",
    "print(f\"    ANOVA F-test per {len(anova_df)} feature\")\n",
    "print(f\"    Top 5 feature per F-statistic:\")\n",
    "print(anova_df.head()[['Feature', 'F_Statistic']].to_string(index=False))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.6 Random Forest Importance**\n",
    "\n",
    "**Teoria:** Random Forest calcola **Feature Importance** come **Mean Decrease in Impurity (MDI)** durante il training.\n",
    "\n",
    "**Come Funziona:**\n",
    "1. RF costruisce N alberi\n",
    "2. Ogni split su feature X riduce l'impurity (Gini o Entropy)\n",
    "3. Importance(X) = Media delle riduzioni di impurity su tutti gli alberi\n",
    "\n",
    "**Vantaggi:**\n",
    "- Cattura **interazioni non lineari** tra feature\n",
    "- Robusto a scale diverse (normalizzazione non richiesta)\n",
    "\n",
    "**Bias Noto:**\n",
    "RF tende a favorire feature con alta cardinalit√†. Per questo usiamo Consensus con altri metodi.\n",
    "\n",
    "**`class_weight='balanced'`:** Compensa lo sbilanciamento di CIC-IDS-2017 pesando inversamente alla frequenza di classe."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\n6. RF Importance (Training...)\")\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=STATE_VARS['RF_N_ESTIMATORS'],\n",
    "    random_state=STATE_VARS['RANDOM_SEED'],\n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1,\n",
    "    max_depth=20,\n",
    ")\n",
    "rf.fit(X_train_c, y_train_encoded)\n",
    "\n",
    "rf_importance = pd.DataFrame({\n",
    "    'Feature': X_train_c.columns,\n",
    "    'Importance': rf.feature_importances_,\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "rf_importance.to_csv(os.path.join(INTERMEDIATE_PATH, \"13_rf_feature_importance.csv\"), index=False)\n",
    "print(f\"    {len(rf_importance)} feature analizzate\")\n",
    "print(f\"    Top 5: {rf_importance.head(5)['Feature'].tolist()}\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_20_rf = rf_importance.head(20)\n",
    "plt.barh(range(len(top_20_rf)), top_20_rf['Importance'], color='steelblue', alpha=0.8)\n",
    "plt.yticks(range(len(top_20_rf)), top_20_rf['Feature'])\n",
    "plt.xlabel('Importanza (Mean Decrease in Impurity)', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Top 20 Feature - Random Forest Importance', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(IMG_PATH, \"07_rf_feature_importance.png\"), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.7 Consensus Ranking & Selezione Finale**\n",
    "\n",
    "**Teoria:** **Ensemble Feature Selection** aggrega ranking di metodi multipli per identificare feature **robuste** su criteri diversi.\n",
    "\n",
    "**Problema dei Metodi Singoli:**\n",
    "- Correlation: Bias verso relazioni lineari\n",
    "- MI: Pu√≤ overfit con pochi campioni per valore discreto\n",
    "- ANOVA: Sensibile a outlier e non-normalit√†\n",
    "- RF: Bias verso alta cardinalit√†\n",
    "\n",
    "**Soluzione SOTA (Tripathi et al., 2024):**\n",
    "\n",
    "### **Consensus Ranking Formula:**\n",
    "Per ogni feature X:\n",
    "1. Rank_Corr(X): Posizione nel ranking Spearman\n",
    "2. Rank_MI(X): Posizione nel ranking MI\n",
    "3. Rank_ANOVA(X): Posizione nel ranking F-statistic\n",
    "4. Rank_RF(X): Posizione nel ranking Importance\n",
    "\n",
    "**Average_Rank(X) = (Rank_Corr + Rank_MI + Rank_ANOVA + Rank_RF) / 4**\n",
    "\n",
    "### **Selezione Top-20:**\n",
    "Selezioniamo le **20 feature con Average_Rank pi√π basso** (ranking migliore).\n",
    "\n",
    "**Vantaggi:**\n",
    "1. **Robustezza**: Feature che performano bene su criteri multipli\n",
    "2. **Diversit√†**: Combina prospettive lineari, non lineari, embedded\n",
    "3. **Riduzione Overfitting**: Evita bias di metodo singolo"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# G. Consensus Ranking\n",
    "print(\"\\n7. Consensus Ranking...\")\n",
    "\n",
    "# Normalizza ranking (1 = migliore)\n",
    "corr_df['Corr_Rank'] = corr_df['SpearmanCorr'].rank(ascending=False)\n",
    "mi_df['MI_Rank'] = mi_df['MI_Score'].rank(ascending=False)\n",
    "anova_df['ANOVA_Rank'] = anova_df['F_Statistic'].rank(ascending=False)\n",
    "rf_importance['RF_Rank'] = rf_importance['Importance'].rank(ascending=False)\n",
    "\n",
    "# Merge tutti i ranking\n",
    "consensus = pd.DataFrame({'Feature': X_train_c.columns})\n",
    "consensus = consensus.merge(corr_df[['Feature', 'Corr_Rank']], on='Feature', how='left')\n",
    "consensus = consensus.merge(mi_df[['Feature', 'MI_Rank']], on='Feature', how='left')\n",
    "consensus = consensus.merge(anova_df[['Feature', 'ANOVA_Rank']], on='Feature', how='left')\n",
    "consensus = consensus.merge(rf_importance[['Feature', 'RF_Rank']], on='Feature', how='left')\n",
    "\n",
    "# Calcola ranking medio\n",
    "consensus['Average_Rank'] = consensus[['Corr_Rank', 'MI_Rank', 'ANOVA_Rank', 'RF_Rank']].mean(axis=1)\n",
    "consensus = consensus.sort_values('Average_Rank')\n",
    "\n",
    "consensus.to_csv(os.path.join(INTERMEDIATE_PATH, \"14_consensus_ranking.csv\"), index=False)\n",
    "\n",
    "print(f\"    Consensus Ranking calcolato per {len(consensus)} feature\")\n",
    "print(f\"    Top 10 feature per consenso:\")\n",
    "print(consensus.head(10)[['Feature', 'Average_Rank']].to_string(index=False))\n",
    "\n",
    "# --- SELEZIONE TOP-N FEATURES ---\n",
    "print(f\"\\n Selezione Top-{STATE_VARS['N_FEATURES_FINAL']} feature dal Consensus Ranking...\")\n",
    "top_n_features = consensus.head(STATE_VARS['N_FEATURES_FINAL'])['Feature'].tolist()\n",
    "\n",
    "X_train_final = X_train_c.loc[:, top_n_features]\n",
    "\n",
    "print(f\"    Feature Finali Selezionate: {len(top_n_features)}\")\n",
    "print(f\"\\n Lista Feature Finali:\")\n",
    "for i, feat in enumerate(top_n_features, 1):\n",
    "    print(f\"   {i:2d}. {feat}\")\n",
    "\n",
    "\n",
    "# Plot Consensus Ranking Comparison\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "top_20_consensus = consensus.head(20)\n",
    "\n",
    "x = np.arange(len(top_20_consensus))\n",
    "width = 0.2\n",
    "\n",
    "ax.barh(x - 1.5*width, top_20_consensus['Corr_Rank'], width, label='Correlation', alpha=0.8)\n",
    "ax.barh(x - 0.5*width, top_20_consensus['MI_Rank'], width, label='Mutual Information', alpha=0.8)\n",
    "ax.barh(x + 0.5*width, top_20_consensus['ANOVA_Rank'], width, label='ANOVA F-test', alpha=0.8)\n",
    "ax.barh(x + 1.5*width, top_20_consensus['RF_Rank'], width, label='Random Forest', alpha=0.8)\n",
    "\n",
    "ax.set_yticks(x)\n",
    "ax.set_yticklabels(top_20_consensus['Feature'])\n",
    "ax.set_xlabel('Ranking Position (lower = better)', fontsize=12)\n",
    "ax.set_ylabel('Feature', fontsize=12)\n",
    "ax.set_title('Consensus Ranking - Top 20 Features (Comparison dei 4 Metodi)', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='lower right')\n",
    "ax.invert_yaxis()\n",
    "ax.invert_xaxis()  # Ranking pi√π basso (migliore) a sinistra\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(IMG_PATH, \"08_consensus_ranking_comparison.png\"), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"    Grafico salvato: {os.path.join(IMG_PATH, '08_consensus_ranking_comparison.png')}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Applicazione Trasformazioni a Val/Test**\n",
    "\n",
    "### **Anti-Leakage Policy**\n",
    "\n",
    "Applichiamo le **stesse trasformazioni** (rimozione feature) a Val e Test usando le maschere calcolate su Train.\n",
    "\n",
    "**CRITICAL:** Val e Test NON hanno influenzato la Feature Selection. Questo garantisce:\n",
    "1. **No Data Leakage**: Statistiche calcolate solo su Train\n",
    "2. **Valutazione Onesta**: Val/Test simulano dati mai visti\n",
    "3. **Generalizzazione Reale**: Performance su Val/Test riflette deployment\n",
    "\n",
    "**Verifica Coerenza:** Train, Val, Test devono avere la stessa shape in colonne."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"[5/5] Applicazione trasformazioni a Val/Test...\")\n",
    "\n",
    "# Applica stesse maschere a Val e Test\n",
    "X_val_final = X_val.loc[:, top_n_features]\n",
    "X_test_final = X_test.loc[:, top_n_features]\n",
    "\n",
    "print(f\"\\n Dataset Finali:\")\n",
    "print(f\"   Train: {X_train_final.shape}\")\n",
    "print(f\"   Val:   {X_val_final.shape}\")\n",
    "print(f\"   Test:  {X_test_final.shape}\")\n",
    "\n",
    "# Verifica coerenza\n",
    "assert list(X_train_final.columns) == list(X_val_final.columns) == list(X_test_final.columns), \\\n",
    "    \" ERRORE: Le colonne di Train/Val/Test non coincidono!\"\n",
    "\n",
    "print(\"\\n Verifica coerenza: OK - Tutte le colonne coincidono\")\n",
    "\n",
    "# Heatmap correlazione tra le feature finali selezionate\n",
    "plt.figure(figsize=(14, 12))\n",
    "corr_final = X_train_final.corr()\n",
    "mask = np.triu(np.ones_like(corr_final, dtype=bool))\n",
    "sns.heatmap(corr_final, mask=mask, annot=False, cmap='RdBu_r', center=0,\n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title(f'Correlazione tra le {len(top_n_features)} Feature Finali Selezionate',\n",
    "          fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(IMG_PATH, \"09_final_features_correlation_heatmap.png\"), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"    Grafico salvato: {os.path.join(IMG_PATH, '09_final_features_correlation_heatmap.png')}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. Salvataggio Dataset Processati**\n",
    "\n",
    "Salviamo i dataset finali in formato **Parquet** (compresso, efficiente) per il prossimo notebook.\n",
    "\n",
    "**Output:**\n",
    "- X_train.parquet, y_train.parquet\n",
    "- X_val.parquet, y_val.parquet\n",
    "- X_test.parquet, y_test.parquet\n",
    "- 20_selected_features.json (lista feature finali)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\n Salvataggio dataset processati...\")\n",
    "\n",
    "# Salva Train\n",
    "X_train_final.to_parquet(\n",
    "    os.path.join(OUTPUT_PATH, \"X_train.parquet\"),\n",
    "    index=False,\n",
    "    compression='snappy'\n",
    ")\n",
    "y_train.to_frame().to_parquet(\n",
    "    os.path.join(OUTPUT_PATH, \"y_train.parquet\"),\n",
    "    index=False,\n",
    "    compression='snappy'\n",
    ")\n",
    "\n",
    "# Salva Val\n",
    "X_val_final.to_parquet(\n",
    "    os.path.join(OUTPUT_PATH, \"X_val.parquet\"),\n",
    "    index=False,\n",
    "    compression='snappy'\n",
    ")\n",
    "y_val.to_frame().to_parquet(\n",
    "    os.path.join(OUTPUT_PATH, \"y_val.parquet\"),\n",
    "    index=False,\n",
    "    compression='snappy'\n",
    ")\n",
    "\n",
    "# Salva Test\n",
    "X_test_final.to_parquet(\n",
    "    os.path.join(OUTPUT_PATH, \"X_test.parquet\"),\n",
    "    index=False,\n",
    "    compression='snappy'\n",
    ")\n",
    "y_test.to_frame().to_parquet(\n",
    "    os.path.join(OUTPUT_PATH, \"y_test.parquet\"),\n",
    "    index=False,\n",
    "    compression='snappy'\n",
    ")\n",
    "\n",
    "# Salva lista feature finali\n",
    "final_features = {'selected_features': top_n_features}\n",
    "with open(os.path.join(INTERMEDIATE_PATH, \"15_selected_features.json\"), 'w') as f:\n",
    "    json.dump(final_features, f, indent=2)\n",
    "\n",
    "print(\"\\n COMPLETATO! Dataset salvati in:\")\n",
    "print(f\"   {OUTPUT_PATH}\")\n",
    "print(f\"\\n Feature finali: {len(top_n_features)}\")\n",
    "print(f\"   Riduzione: {X_train.shape[1]} ‚Üí {len(top_n_features)} ({100*(1-len(top_n_features)/X_train.shape[1]):.1f}% riduzione)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8. Report Riepilogativo**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" REPORT FINALE - FEATURE ENGINEERING & SELECTION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüîπ Feature Iniziali (post-sanitizzazione): {X_train.shape[1]}\")\n",
    "print(f\"üîπ Dopo Variance Threshold: {X_train_v.shape[1]} (-{removed_var})\")\n",
    "print(f\"üîπ Dopo Correlation Filter (‚â•0.95): {X_train_c.shape[1]} (-{len(to_drop_corr)})\")\n",
    "print(f\"üîπ Dopo Consensus Ranking (Top-{STATE_VARS['N_FEATURES_FINAL']}): {len(top_n_features)}\")\n",
    "print(f\"\\n Riduzione Totale: {100*(1-len(top_n_features)/X_train.shape[1]):.1f}%\")\n",
    "print(f\"\\n  Output salvati in:\")\n",
    "print(f\"   - Dataset processati: {OUTPUT_PATH}\")\n",
    "print(f\"   - Analisi intermedie: {INTERMEDIATE_PATH}\")\n",
    "print(f\"\\n  Feature Finali Selezionate ({len(top_n_features)}):\")\n",
    "for i, feat in enumerate(top_n_features, 1):\n",
    "    avg_rank = consensus[consensus['Feature'] == feat]['Average_Rank'].values[0]\n",
    "    print(f\"   {i:2d}. {feat:<30s} (Avg Rank: {avg_rank:.2f})\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" Pronto per il Notebook 03: Model Training & Evaluation\")\n",
    "print(\"=\"*60)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
